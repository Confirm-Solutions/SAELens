{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYWV3AuAxXjO"
      },
      "source": [
        "# Setup & loading stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SCvWyLnxxEpP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "env: TOKENIZERS_PARALLELISM=true\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from sae_lens import SAE, HookedSAETransformer\n",
        "\n",
        "import torch\n",
        "\n",
        "from sae_vis.data_config_classes import SaeVisConfig\n",
        "from sae_vis.data_storing_fns import SaeVisData\n",
        "\n",
        "torch.set_grad_enabled(False)\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "%env TOKENIZERS_PARALLELISM=true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qiH7-j2NzVA1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained model pythia-70m into HookedTransformer\n",
            "Changing model dtype to torch.float32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspace/SAELens/sae_lens/sae.py:159: UserWarning: \n",
            "This SAE has non-empty model_from_pretrained_kwargs. \n",
            "For optimal performance, load the model like so:\n",
            "model = HookedSAETransformer.from_pretrained_no_processing(..., **cfg.model_from_pretrained_kwargs)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens loaded for attn-only model: tokens.shape=torch.Size([4096, 64])\n",
            "Alive features: 12730/32768\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = HookedSAETransformer.from_pretrained_no_processing(\n",
        "    \"pythia-70m\", device=device\n",
        ").to(torch.float32)\n",
        "sae = SAE.load_from_disk(\n",
        "    \"/workspace/SAELens/checkpoints/pythia-70m-sae-100m/fl09x50p/final_100007936\"\n",
        ").to(device=device, dtype=torch.float32)\n",
        "\n",
        "batch_size = 4096\n",
        "batch_size_for_computing_alive_feats = 512\n",
        "seq_len = 64\n",
        "\n",
        "original_dataset = load_dataset(\n",
        "    sae.cfg.dataset_path, split=\"train\", streaming=True, trust_remote_code=True\n",
        ")\n",
        "\n",
        "original_dataset = original_dataset.map(lambda x: model.tokenizer(x[\"text\"]))\n",
        "original_dataset = original_dataset.filter(lambda x: len(x[\"input_ids\"]) >= seq_len)\n",
        "\n",
        "\n",
        "attn_tokens_as_list = [\n",
        "    x[\"input_ids\"][: seq_len - 1] for (_, x) in zip(range(batch_size), original_dataset)\n",
        "]\n",
        "tokens = torch.tensor(attn_tokens_as_list, device=device)\n",
        "bos_token = torch.tensor(\n",
        "    [model.tokenizer.bos_token_id for _ in range(batch_size)], device=device\n",
        ")  # type: ignore\n",
        "tokens = torch.cat([bos_token.unsqueeze(1), tokens], dim=1)\n",
        "print(f\"Tokens loaded for attn-only model: {tokens.shape=}\")\n",
        "\n",
        "_, cache = model.run_with_cache_with_saes(\n",
        "    tokens[:batch_size_for_computing_alive_feats],\n",
        "    saes=[sae],\n",
        "    names_filter=(post_acts_hook := f\"{sae.cfg.hook_name}.hook_sae_acts_post\"),\n",
        "    stop_at_layer=sae.cfg.hook_layer + 1,\n",
        ")\n",
        "acts = cache[post_acts_hook]\n",
        "alive_feats = (acts.flatten(0, 1) > 1e-8).any(dim=0).nonzero().squeeze().tolist()\n",
        "print(f\"Alive features: {len(alive_feats)}/{sae.cfg.d_sae}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'togethercomputer/RedPajama-Data-1T-Sample'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sae.cfg.dataset_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'blocks.0.hook_mlp_out'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sae.cfg.hook_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "sae_vis_data = SaeVisData.create(\n",
        "    sae,\n",
        "    model=model,\n",
        "    tokens=tokens,\n",
        "    cfg=SaeVisConfig(features=alive_feats[:32]),\n",
        ")\n",
        "sae_vis_data.save_feature_centric_vis(filename=\"demo_feature_vis_pythia70m_topk.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "No active feats found for any prompt tokens",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msae_vis_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_prompt_centric_vis\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwrite fibonacci sequence in python\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdemo_prompt_vis_pythia70m_topk.html\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SAELens/sae_vis/sae_vis/data_storing_fns.py:966\u001b[39m, in \u001b[36mSaeVisData.save_prompt_centric_vis\u001b[39m\u001b[34m(self, filename, prompt, metric, seq_pos, num_top_features, verbose)\u001b[39m\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m PROMPT_DATA.get(first_key := \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m|\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseq_keys[seq_pos\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, []) == []:\n\u001b[32m    965\u001b[39m     valid_keys = [k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m PROMPT_DATA.items() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v) > \u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m966\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(valid_keys) > \u001b[32m0\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mNo active feats found for any prompt tokens\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    967\u001b[39m     first_key = valid_keys[\u001b[32m0\u001b[39m]\n\u001b[32m    968\u001b[39m     first_metric = first_key.split(\u001b[33m\"\u001b[39m\u001b[33m|\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m0\u001b[39m]\n",
            "\u001b[31mAssertionError\u001b[39m: No active feats found for any prompt tokens"
          ]
        }
      ],
      "source": [
        "sae_vis_data.save_prompt_centric_vis(\n",
        "    prompt=\"write fibonacci sequence in python\",\n",
        "    filename=\"demo_prompt_vis_pythia70m_topk.html\",\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "KYWV3AuAxXjO"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
