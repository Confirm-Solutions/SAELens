{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYWV3AuAxXjO"
      },
      "source": [
        "# Setup & loading stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SCvWyLnxxEpP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: mps\n",
            "env: TOKENIZERS_PARALLELISM=true\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from sae_lens import SAE, HookedSAETransformer\n",
        "\n",
        "import torch\n",
        "\n",
        "from sae_vis.data_config_classes import SaeVisConfig\n",
        "from sae_vis.data_storing_fns import SaeVisData\n",
        "\n",
        "torch.set_grad_enabled(False)\n",
        "# if torch.cuda.is_available():\n",
        "#     device = torch.device(\"cuda\")\n",
        "# elif torch.backends.mps.is_available():\n",
        "#     device = torch.device(\"mps\")\n",
        "# else:\n",
        "#     device = torch.device(\"cpu\")\n",
        "device = torch.device(\"mps\")\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "%env TOKENIZERS_PARALLELISM=true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qiH7-j2NzVA1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained model pythia-14m into HookedTransformer\n",
            "Changing model dtype to torch.float32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sidbaskaran/Desktop/research/SAELens/sae_lens/sae.py:159: UserWarning: \n",
            "This SAE has non-empty model_from_pretrained_kwargs. \n",
            "For optimal performance, load the model like so:\n",
            "model = HookedSAETransformer.from_pretrained_no_processing(..., **cfg.model_from_pretrained_kwargs)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens loaded for attn-only model: tokens.shape=torch.Size([4096, 64])\n",
            "Alive features: 2726/8192\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = HookedSAETransformer.from_pretrained_no_processing(\n",
        "    \"pythia-14m\", device=device\n",
        ").to(torch.float32)\n",
        "sae = SAE.load_from_disk(\n",
        "    \"/Users/sidbaskaran/Desktop/research/SAELens/checkpoints/hfvusbuw/final_10000384\"\n",
        ").to(device=device, dtype=torch.float32)\n",
        "\n",
        "batch_size = 4096\n",
        "batch_size_for_computing_alive_feats = 512\n",
        "seq_len = 64\n",
        "\n",
        "original_dataset = load_dataset(\n",
        "    sae.cfg.dataset_path, split=\"train\", streaming=True, trust_remote_code=True\n",
        ")\n",
        "\n",
        "original_dataset = original_dataset.map(lambda x: model.tokenizer(x[\"text\"]))\n",
        "original_dataset = original_dataset.filter(lambda x: len(x[\"input_ids\"]) >= seq_len)\n",
        "\n",
        "\n",
        "attn_tokens_as_list = [\n",
        "    x[\"input_ids\"][: seq_len - 1] for (_, x) in zip(range(batch_size), original_dataset)\n",
        "]\n",
        "tokens = torch.tensor(attn_tokens_as_list, device=device)\n",
        "bos_token = torch.tensor(\n",
        "    [model.tokenizer.bos_token_id for _ in range(batch_size)], device=device\n",
        ")  # type: ignore\n",
        "tokens = torch.cat([bos_token.unsqueeze(1), tokens], dim=1)\n",
        "print(f\"Tokens loaded for attn-only model: {tokens.shape=}\")\n",
        "\n",
        "_, cache = model.run_with_cache_with_saes(\n",
        "    tokens[:batch_size_for_computing_alive_feats],\n",
        "    saes=[sae],\n",
        "    names_filter=(post_acts_hook := f\"{sae.cfg.hook_name}.hook_sae_acts_post\"),\n",
        "    stop_at_layer=sae.cfg.hook_layer + 1,\n",
        ")\n",
        "acts = cache[post_acts_hook]\n",
        "alive_feats = (acts.flatten(0, 1) > 1e-8).any(dim=0).nonzero().squeeze().tolist()\n",
        "print(f\"Alive features: {len(alive_feats)}/{sae.cfg.d_sae}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'togethercomputer/RedPajama-Data-1T-Sample'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sae.cfg.dataset_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'blocks.0.hook_mlp_out'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sae.cfg.hook_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "sae_vis_data = SaeVisData.create(\n",
        "    sae,\n",
        "    model=model,\n",
        "    tokens=tokens,\n",
        "    cfg=SaeVisConfig(features=alive_feats[:32]),\n",
        ")\n",
        "sae_vis_data.save_feature_centric_vis(filename=\"demo_feature_vis_pythia70m_topk.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "sae_vis_data.save_prompt_centric_vis(\n",
        "    prompt=\"write fibonacci sequence in python\",\n",
        "    filename=\"demo_prompt_vis_pythia70m_topk.html\",\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "KYWV3AuAxXjO"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
