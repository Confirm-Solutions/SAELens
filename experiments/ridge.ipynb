{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max absolute difference between batched vs loop: 5.588e-08\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# ——————————————————————————————————————————————————————————\n",
    "# Configuration\n",
    "torch.manual_seed(0)\n",
    "B, N, P, K = 5, 20, 15, 4   # batch size, samples, features, top-k\n",
    "alpha = 0.5                 # exponent for penalty\n",
    "\n",
    "# Random inputs\n",
    "X      = torch.randn(B, N, P)       # [B, N, P]\n",
    "Y      = torch.randn(B, N, 1)       # [B, N, 1]\n",
    "scores = torch.randn(B, P)          # [B, P]\n",
    "\n",
    "# ——————————————————————————————————————————————————————————\n",
    "def batched_beta_full(X, Y, scores, K, alpha):\n",
    "    topk_vals, topk_idx = scores.topk(K, dim=1)              # [B, K]\n",
    "    idx_exp = topk_idx.unsqueeze(1).expand(-1, X.size(1), -1)# [B, N, K]\n",
    "    X_topk = torch.gather(X, 2, idx_exp)                     # [B, N, K]\n",
    "    Xt = X_topk.transpose(1, 2)                              # [B, K, N]\n",
    "    penalty = torch.diag_embed(1.0 / (topk_vals**alpha))     # [B, K, K]\n",
    "    XtX = torch.bmm(Xt, X_topk) + penalty                    # [B, K, K]\n",
    "    Xty = torch.bmm(Xt, Y)                                   # [B, K, 1]\n",
    "    beta = torch.linalg.solve(XtX, Xty).squeeze(-1)          # [B, K]\n",
    "    beta_full = torch.zeros(B, P)\n",
    "    beta_full.scatter_(1, topk_idx, beta)                    # [B, P]\n",
    "    return beta_full\n",
    "\n",
    "def loop_beta_full(X, Y, scores, K, alpha):\n",
    "    B, _, P = X.shape\n",
    "    beta_full = torch.zeros(B, P)\n",
    "    for b in range(B):\n",
    "        vals_b, idx_b = scores[b].topk(K)\n",
    "        Xb, Yb = X[b], Y[b]\n",
    "        Xb_topk = Xb[:, idx_b]                                # [N, K]\n",
    "        penalty_b = torch.diag(1.0 / (vals_b**alpha))         # [K, K]\n",
    "        XtXb = Xb_topk.t() @ Xb_topk + penalty_b              # [K, K]\n",
    "        Xtyb = Xb_topk.t() @ Yb                               # [K, 1]\n",
    "        betab = torch.linalg.solve(XtXb, Xtyb).squeeze(-1)    # [K]\n",
    "        beta_full[b, idx_b] = betab\n",
    "    return beta_full\n",
    "\n",
    "# ——————————————————————————————————————————————————————————\n",
    "# Compare reconstructions\n",
    "beta_b = batched_beta_full(X, Y, scores, K, alpha)\n",
    "beta_l = loop_beta_full(   X, Y, scores, K, alpha)\n",
    "\n",
    "max_diff = (beta_b - beta_l).abs().max().item()\n",
    "print(f\"Max absolute difference between batched vs loop: {max_diff:.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8832), tensor(0.8832))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_b.norm(), beta_l.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
