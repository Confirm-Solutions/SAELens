# @package _global_
# Model configuration options

# Model specification
model_name: "gelu-2l"
model_class_name: "HookedTransformer"

# Hook configuration
hook_name: "blocks.0.hook_mlp_out"
hook_eval: "NOT_IN_USE"
hook_layer: 0
hook_head_index: null

# Model dimensions
d_in: 512
d_sae: null  # Will be calculated from expansion_factor if not set

# Model runtime options
model_kwargs: {}
model_from_pretrained_kwargs: null  # Will be set automatically based on model_class_name

# Device and performance
device: "cpu"
act_store_device: "with_model"  # will be set by post init if with_model
seed: 42
dtype: "float32"
