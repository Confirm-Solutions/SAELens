# @package _global_
# Small-scale training configuration for quick experiments

defaults:
  - default

# Training tokens and batching
training_tokens: 100_000
train_batch_size_tokens: 1024
store_batch_size_prompts: 16
n_batches_in_buffer: 8 
